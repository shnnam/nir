{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SC3IdFKs8pCd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model import Siren\n",
    "from util import get_mgrid, jacobian, VideoFitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(path, total_steps, lambda_interf=0.01, lambda_flow=0.02, verbose=True, steps_til_summary=100):\n",
    "    g = Siren(in_features=3, out_features=3, hidden_features=256,\n",
    "              hidden_layers=5, outermost_linear=True)\n",
    "    g.cuda()\n",
    "    f1 = Siren(in_features=3, out_features=3, hidden_features=256, \n",
    "               hidden_layers=5, outermost_linear=True)\n",
    "    f1.cuda()\n",
    "    f2 = Siren(in_features=3, out_features=1, hidden_features=256,\n",
    "               hidden_layers=5, outermost_linear=True)\n",
    "    f2.cuda()\n",
    "\n",
    "    optim = torch.optim.Adam(lr=1e-4, params=chain(g.parameters(), f1.parameters(), f2.parameters()))\n",
    "\n",
    "    v = VideoFitting(path)\n",
    "    videoloader = DataLoader(v, batch_size=1, pin_memory=True, num_workers=0)\n",
    "    model_input, ground_truth = next(iter(videoloader))\n",
    "    model_input, ground_truth = model_input[0].cuda(), ground_truth[0].cuda()\n",
    "\n",
    "    batch_size = (v.H * v.W) // 4\n",
    "    for step in range(total_steps):\n",
    "        start = (step * batch_size) % len(model_input)\n",
    "        end = min(start + batch_size, len(model_input))\n",
    "\n",
    "        xyt = model_input[start:end].requires_grad_()\n",
    "        h = g(xyt)\n",
    "        xy_, w = xyt[:, :-1] + h[:, :-1], h[:, [-1]]\n",
    "        o_scene = torch.sigmoid(f1(torch.cat((xy_, w), -1)))\n",
    "        o_rain = torch.sigmoid(f2(xyt))\n",
    "        o = (1 - o_rain) * o_scene + o_rain\n",
    "        loss_recon = (o - ground_truth[start:end]).abs().mean()\n",
    "        loss_interf = o_rain.abs().mean()\n",
    "        loss_flow = jacobian(h, xyt).abs().mean()\n",
    "        loss = loss_recon + lambda_interf * loss_interf + lambda_flow * loss_flow\n",
    "\n",
    "        if not step % steps_til_summary:\n",
    "            print(\"Step [%04d/%04d]: recon=%0.8f, interf=%0.4f, flow=%0.4f\" % (step, total_steps, loss_recon, loss_interf, loss_flow))\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    \n",
    "    return g, f1, f2, v.video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, f1, f2, orig = train('./data/rain', 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    N, _, H, W = orig.size()\n",
    "    xyt = get_mgrid([H, W, N]).cuda()\n",
    "    h = g(xyt)\n",
    "    xy_, w = xyt[:, :-1] + h[:, :-1], h[:, [-1]]\n",
    "    o_scene = torch.sigmoid(f1(torch.cat((xy_, w), -1)))\n",
    "    o_rain = torch.sigmoid(f2(xyt))\n",
    "    o_scene = o_scene.view(H, W, N, 3).permute(2, 0, 1, 3).cpu().detach().numpy()\n",
    "    o_rain = o_rain.view(H, W, N).permute(2, 0, 1).cpu().detach().numpy()\n",
    "    o_scene = (o_scene * 255).astype(np.uint8)\n",
    "    o_rain = (o_rain * 255).astype(np.uint8)\n",
    "    o_scene = [o_scene[i] for i in range(len(o_scene))]\n",
    "    o_rain = [o_rain[i] for i in range(len(o_rain))]\n",
    "    orig = orig.permute(0, 2, 3, 1).detach().numpy()\n",
    "    orig = (orig * 255).astype(np.uint8)\n",
    "    orig = [orig[i] for i in range(len(orig))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save out video\n",
    "# ! pip install --user imageio imageio-ffmpeg\n",
    "import imageio\n",
    "fn_orig = os.path.join('./data/rain_orig.mp4')\n",
    "fn_scene = os.path.join('./data/rain_scene.mp4')\n",
    "fn_rain = os.path.join('./data/rain_interf.mp4')\n",
    "imageio.mimwrite(fn_orig, orig, fps=1)\n",
    "imageio.mimwrite(fn_scene, o_scene, fps=1)\n",
    "imageio.mimwrite(fn_rain, o_rain, fps=1)\n",
    "\n",
    "# Display video inline\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "data_url_orig = \"data:video/mp4;base64,\" + b64encode(open(fn_orig, 'rb').read()).decode()\n",
    "data_url_scene = \"data:video/mp4;base64,\" + b64encode(open(fn_scene, 'rb').read()).decode()\n",
    "data_url_rain = \"data:video/mp4;base64,\" + b64encode(open(fn_rain, 'rb').read()).decode()\n",
    "HTML(f'''\n",
    "<video width=512 controls autoplay loop>\n",
    "      <source src=\"{data_url_orig}\" type=\"video/mp4\">\n",
    "</video>\n",
    "<video width=512 controls autoplay loop>\n",
    "      <source src=\"{data_url_scene}\" type=\"video/mp4\">\n",
    "</video>\n",
    "<video width=512 controls autoplay loop>\n",
    "      <source src=\"{data_url_rain}\" type=\"video/mp4\">\n",
    "</video>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "explore_siren.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch-1.8",
   "language": "python",
   "name": "pytorch-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
